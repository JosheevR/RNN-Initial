{
  "cells": [
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import SimpleRNN, LSTM, Dense",
      "metadata": {
        "source_hash": "db7b14fa",
        "execution_start": 1720545948830,
        "execution_millis": 2157,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "395613e13b3e47ab8efda461c1e7d199",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-07-09 17:25:48.790275: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2024-07-09 17:25:48.959507: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2024-07-09 17:25:48.959532: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2024-07-09 17:25:48.998577: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-07-09 17:25:49.805553: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2024-07-09 17:25:49.805629: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2024-07-09 17:25:49.805639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "execution_count": 1,
      "block_group": "395613e13b3e47ab8efda461c1e7d199",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "data = list(range(501))",
      "metadata": {
        "source_hash": "216a73fd",
        "execution_start": 1720545950991,
        "execution_millis": 100,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "9c5beb73e90a45d2a53fb4ade8bd592f",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": 2,
      "block_group": "7c66192aaec64034b70109416ab48b78",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "window_size = 3\n\nX_train = []\ny_train = []\n\nfor i in range(len(data)-window_size):\n    X_train.append(data[i:i+window_size])\n    y_train.append(data[i+window_size])\n\nX_test = [[501, 502, 503], [502,503,504], [503,504,505]]\ny_test = [504,505,506]",
      "metadata": {
        "source_hash": "14284115",
        "execution_start": 1720545950997,
        "execution_millis": 326,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "726093b713924659ae6c6e3dd44bb6e5",
        "deepnote_cell_type": "code"
      },
      "outputs": [],
      "outputs_reference": null,
      "execution_count": 3,
      "block_group": "a2cb9ceb39d34d659ec7caf69ee9f9fb",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "print('X_train: ', X_train)\nprint('y_train: ', y_train)\nprint('\\n')\nprint('X_test: ', X_test)\nprint('y_test: ', y_test)",
      "metadata": {
        "source_hash": "8c7ff34c",
        "execution_start": 1720545951004,
        "execution_millis": 320,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "48e1612295ec4f86a48887fedf6abfc9",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "X_train:  [[0, 1, 2], [1, 2, 3], [2, 3, 4], [3, 4, 5], [4, 5, 6], [5, 6, 7], [6, 7, 8], [7, 8, 9], [8, 9, 10], [9, 10, 11], [10, 11, 12], [11, 12, 13], [12, 13, 14], [13, 14, 15], [14, 15, 16], [15, 16, 17], [16, 17, 18], [17, 18, 19], [18, 19, 20], [19, 20, 21], [20, 21, 22], [21, 22, 23], [22, 23, 24], [23, 24, 25], [24, 25, 26], [25, 26, 27], [26, 27, 28], [27, 28, 29], [28, 29, 30], [29, 30, 31], [30, 31, 32], [31, 32, 33], [32, 33, 34], [33, 34, 35], [34, 35, 36], [35, 36, 37], [36, 37, 38], [37, 38, 39], [38, 39, 40], [39, 40, 41], [40, 41, 42], [41, 42, 43], [42, 43, 44], [43, 44, 45], [44, 45, 46], [45, 46, 47], [46, 47, 48], [47, 48, 49], [48, 49, 50], [49, 50, 51], [50, 51, 52], [51, 52, 53], [52, 53, 54], [53, 54, 55], [54, 55, 56], [55, 56, 57], [56, 57, 58], [57, 58, 59], [58, 59, 60], [59, 60, 61], [60, 61, 62], [61, 62, 63], [62, 63, 64], [63, 64, 65], [64, 65, 66], [65, 66, 67], [66, 67, 68], [67, 68, 69], [68, 69, 70], [69, 70, 71], [70, 71, 72], [71, 72, 73], [72, 73, 74], [73, 74, 75], [74, 75, 76], [75, 76, 77], [76, 77, 78], [77, 78, 79], [78, 79, 80], [79, 80, 81], [80, 81, 82], [81, 82, 83], [82, 83, 84], [83, 84, 85], [84, 85, 86], [85, 86, 87], [86, 87, 88], [87, 88, 89], [88, 89, 90], [89, 90, 91], [90, 91, 92], [91, 92, 93], [92, 93, 94], [93, 94, 95], [94, 95, 96], [95, 96, 97], [96, 97, 98], [97, 98, 99], [98, 99, 100], [99, 100, 101], [100, 101, 102], [101, 102, 103], [102, 103, 104], [103, 104, 105], [104, 105, 106], [105, 106, 107], [106, 107, 108], [107, 108, 109], [108, 109, 110], [109, 110, 111], [110, 111, 112], [111, 112, 113], [112, 113, 114], [113, 114, 115], [114, 115, 116], [115, 116, 117], [116, 117, 118], [117, 118, 119], [118, 119, 120], [119, 120, 121], [120, 121, 122], [121, 122, 123], [122, 123, 124], [123, 124, 125], [124, 125, 126], [125, 126, 127], [126, 127, 128], [127, 128, 129], [128, 129, 130], [129, 130, 131], [130, 131, 132], [131, 132, 133], [132, 133, 134], [133, 134, 135], [134, 135, 136], [135, 136, 137], [136, 137, 138], [137, 138, 139], [138, 139, 140], [139, 140, 141], [140, 141, 142], [141, 142, 143], [142, 143, 144], [143, 144, 145], [144, 145, 146], [145, 146, 147], [146, 147, 148], [147, 148, 149], [148, 149, 150], [149, 150, 151], [150, 151, 152], [151, 152, 153], [152, 153, 154], [153, 154, 155], [154, 155, 156], [155, 156, 157], [156, 157, 158], [157, 158, 159], [158, 159, 160], [159, 160, 161], [160, 161, 162], [161, 162, 163], [162, 163, 164], [163, 164, 165], [164, 165, 166], [165, 166, 167], [166, 167, 168], [167, 168, 169], [168, 169, 170], [169, 170, 171], [170, 171, 172], [171, 172, 173], [172, 173, 174], [173, 174, 175], [174, 175, 176], [175, 176, 177], [176, 177, 178], [177, 178, 179], [178, 179, 180], [179, 180, 181], [180, 181, 182], [181, 182, 183], [182, 183, 184], [183, 184, 185], [184, 185, 186], [185, 186, 187], [186, 187, 188], [187, 188, 189], [188, 189, 190], [189, 190, 191], [190, 191, 192], [191, 192, 193], [192, 193, 194], [193, 194, 195], [194, 195, 196], [195, 196, 197], [196, 197, 198], [197, 198, 199], [198, 199, 200], [199, 200, 201], [200, 201, 202], [201, 202, 203], [202, 203, 204], [203, 204, 205], [204, 205, 206], [205, 206, 207], [206, 207, 208], [207, 208, 209], [208, 209, 210], [209, 210, 211], [210, 211, 212], [211, 212, 213], [212, 213, 214], [213, 214, 215], [214, 215, 216], [215, 216, 217], [216, 217, 218], [217, 218, 219], [218, 219, 220], [219, 220, 221], [220, 221, 222], [221, 222, 223], [222, 223, 224], [223, 224, 225], [224, 225, 226], [225, 226, 227], [226, 227, 228], [227, 228, 229], [228, 229, 230], [229, 230, 231], [230, 231, 232], [231, 232, 233], [232, 233, 234], [233, 234, 235], [234, 235, 236], [235, 236, 237], [236, 237, 238], [237, 238, 239], [238, 239, 240], [239, 240, 241], [240, 241, 242], [241, 242, 243], [242, 243, 244], [243, 244, 245], [244, 245, 246], [245, 246, 247], [246, 247, 248], [247, 248, 249], [248, 249, 250], [249, 250, 251], [250, 251, 252], [251, 252, 253], [252, 253, 254], [253, 254, 255], [254, 255, 256], [255, 256, 257], [256, 257, 258], [257, 258, 259], [258, 259, 260], [259, 260, 261], [260, 261, 262], [261, 262, 263], [262, 263, 264], [263, 264, 265], [264, 265, 266], [265, 266, 267], [266, 267, 268], [267, 268, 269], [268, 269, 270], [269, 270, 271], [270, 271, 272], [271, 272, 273], [272, 273, 274], [273, 274, 275], [274, 275, 276], [275, 276, 277], [276, 277, 278], [277, 278, 279], [278, 279, 280], [279, 280, 281], [280, 281, 282], [281, 282, 283], [282, 283, 284], [283, 284, 285], [284, 285, 286], [285, 286, 287], [286, 287, 288], [287, 288, 289], [288, 289, 290], [289, 290, 291], [290, 291, 292], [291, 292, 293], [292, 293, 294], [293, 294, 295], [294, 295, 296], [295, 296, 297], [296, 297, 298], [297, 298, 299], [298, 299, 300], [299, 300, 301], [300, 301, 302], [301, 302, 303], [302, 303, 304], [303, 304, 305], [304, 305, 306], [305, 306, 307], [306, 307, 308], [307, 308, 309], [308, 309, 310], [309, 310, 311], [310, 311, 312], [311, 312, 313], [312, 313, 314], [313, 314, 315], [314, 315, 316], [315, 316, 317], [316, 317, 318], [317, 318, 319], [318, 319, 320], [319, 320, 321], [320, 321, 322], [321, 322, 323], [322, 323, 324], [323, 324, 325], [324, 325, 326], [325, 326, 327], [326, 327, 328], [327, 328, 329], [328, 329, 330], [329, 330, 331], [330, 331, 332], [331, 332, 333], [332, 333, 334], [333, 334, 335], [334, 335, 336], [335, 336, 337], [336, 337, 338], [337, 338, 339], [338, 339, 340], [339, 340, 341], [340, 341, 342], [341, 342, 343], [342, 343, 344], [343, 344, 345], [344, 345, 346], [345, 346, 347], [346, 347, 348], [347, 348, 349], [348, 349, 350], [349, 350, 351], [350, 351, 352], [351, 352, 353], [352, 353, 354], [353, 354, 355], [354, 355, 356], [355, 356, 357], [356, 357, 358], [357, 358, 359], [358, 359, 360], [359, 360, 361], [360, 361, 362], [361, 362, 363], [362, 363, 364], [363, 364, 365], [364, 365, 366], [365, 366, 367], [366, 367, 368], [367, 368, 369], [368, 369, 370], [369, 370, 371], [370, 371, 372], [371, 372, 373], [372, 373, 374], [373, 374, 375], [374, 375, 376], [375, 376, 377], [376, 377, 378], [377, 378, 379], [378, 379, 380], [379, 380, 381], [380, 381, 382], [381, 382, 383], [382, 383, 384], [383, 384, 385], [384, 385, 386], [385, 386, 387], [386, 387, 388], [387, 388, 389], [388, 389, 390], [389, 390, 391], [390, 391, 392], [391, 392, 393], [392, 393, 394], [393, 394, 395], [394, 395, 396], [395, 396, 397], [396, 397, 398], [397, 398, 399], [398, 399, 400], [399, 400, 401], [400, 401, 402], [401, 402, 403], [402, 403, 404], [403, 404, 405], [404, 405, 406], [405, 406, 407], [406, 407, 408], [407, 408, 409], [408, 409, 410], [409, 410, 411], [410, 411, 412], [411, 412, 413], [412, 413, 414], [413, 414, 415], [414, 415, 416], [415, 416, 417], [416, 417, 418], [417, 418, 419], [418, 419, 420], [419, 420, 421], [420, 421, 422], [421, 422, 423], [422, 423, 424], [423, 424, 425], [424, 425, 426], [425, 426, 427], [426, 427, 428], [427, 428, 429], [428, 429, 430], [429, 430, 431], [430, 431, 432], [431, 432, 433], [432, 433, 434], [433, 434, 435], [434, 435, 436], [435, 436, 437], [436, 437, 438], [437, 438, 439], [438, 439, 440], [439, 440, 441], [440, 441, 442], [441, 442, 443], [442, 443, 444], [443, 444, 445], [444, 445, 446], [445, 446, 447], [446, 447, 448], [447, 448, 449], [448, 449, 450], [449, 450, 451], [450, 451, 452], [451, 452, 453], [452, 453, 454], [453, 454, 455], [454, 455, 456], [455, 456, 457], [456, 457, 458], [457, 458, 459], [458, 459, 460], [459, 460, 461], [460, 461, 462], [461, 462, 463], [462, 463, 464], [463, 464, 465], [464, 465, 466], [465, 466, 467], [466, 467, 468], [467, 468, 469], [468, 469, 470], [469, 470, 471], [470, 471, 472], [471, 472, 473], [472, 473, 474], [473, 474, 475], [474, 475, 476], [475, 476, 477], [476, 477, 478], [477, 478, 479], [478, 479, 480], [479, 480, 481], [480, 481, 482], [481, 482, 483], [482, 483, 484], [483, 484, 485], [484, 485, 486], [485, 486, 487], [486, 487, 488], [487, 488, 489], [488, 489, 490], [489, 490, 491], [490, 491, 492], [491, 492, 493], [492, 493, 494], [493, 494, 495], [494, 495, 496], [495, 496, 497], [496, 497, 498], [497, 498, 499]]\ny_train:  [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500]\n\n\nX_test:  [[501, 502, 503], [502, 503, 504], [503, 504, 505]]\ny_test:  [504, 505, 506]\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "execution_count": 4,
      "block_group": "2ac1a9c7791b4c00b81d6c0cab92c0c2",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "model = Sequential()\nmodel.add(SimpleRNN(50, activation='relu', input_shape=(window_size, 1)))\nmodel.add(Dense(1))\n\n# model = Sequential()\n# model.add(SimpleRNN(25, activation='relu', return_sequences=True, input_shape=(window_size, 1)))\n# model.add(SimpleRNN(25, activation='relu', return_sequences=True))\n# model.add(SimpleRNN(25, activation='relu'))\n# model.add(Dense(1))",
      "metadata": {
        "source_hash": "fcf12521",
        "execution_start": 1720545951084,
        "execution_millis": 245,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "e96d3f6dd77f4f1faaa8115e4816b3fc",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-07-09 17:25:51.009654: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2024-07-09 17:25:51.009685: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2024-07-09 17:25:51.009705: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-f5ed8ee2-3d40-4858-844e-fc002cc3a8df): /proc/driver/nvidia/version does not exist\n2024-07-09 17:25:51.009961: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "execution_count": 5,
      "block_group": "d68a2d27610f407db378e3d3af73e2bb",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "model.compile(loss='mse', optimizer='adam')\nmodel.fit(np.array(X_train), np.array(y_train), epochs=500, verbose=1)",
      "metadata": {
        "source_hash": "9b31ed32",
        "execution_start": 1720545951331,
        "execution_millis": 0,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "ae0c44a1c94c46e49b71e9822ab4c73a",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/500\n16/16 [==============================] - 1s 2ms/step - loss: 45116.7461\nEpoch 2/500\n16/16 [==============================] - 0s 5ms/step - loss: 5934.5327\nEpoch 3/500\n16/16 [==============================] - 0s 5ms/step - loss: 778.8818\nEpoch 4/500\n16/16 [==============================] - 0s 2ms/step - loss: 77.5779\nEpoch 5/500\n16/16 [==============================] - 0s 4ms/step - loss: 37.5720\nEpoch 6/500\n16/16 [==============================] - 0s 2ms/step - loss: 7.8008\nEpoch 7/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.9097\nEpoch 8/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.2590\nEpoch 9/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.1717\nEpoch 10/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.1093\nEpoch 11/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.1007\nEpoch 12/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0976\nEpoch 13/500\n16/16 [==============================] - 0s 4ms/step - loss: 1.0949\nEpoch 14/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0930\nEpoch 15/500\n16/16 [==============================] - 0s 6ms/step - loss: 1.0909\nEpoch 16/500\n16/16 [==============================] - 0s 4ms/step - loss: 1.0908\nEpoch 17/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0866\nEpoch 18/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.0868\nEpoch 19/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0843\nEpoch 20/500\n16/16 [==============================] - 0s 4ms/step - loss: 1.0873\nEpoch 21/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0767\nEpoch 22/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0723\nEpoch 23/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.0711\nEpoch 24/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0742\nEpoch 25/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.0628\nEpoch 26/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0632\nEpoch 27/500\n16/16 [==============================] - 0s 3ms/step - loss: 1.0714\nEpoch 28/500\n16/16 [==============================] - 0s 4ms/step - loss: 1.0557\nEpoch 29/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0527\nEpoch 30/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.0500\nEpoch 31/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.0435\nEpoch 32/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0438\nEpoch 33/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.0379\nEpoch 34/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0316\nEpoch 35/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.0276\nEpoch 36/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0250\nEpoch 37/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0237\nEpoch 38/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.0184\nEpoch 39/500\n16/16 [==============================] - 0s 3ms/step - loss: 1.0127\nEpoch 40/500\n16/16 [==============================] - 0s 4ms/step - loss: 1.0088\nEpoch 41/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0077\nEpoch 42/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0044\nEpoch 43/500\n16/16 [==============================] - 0s 5ms/step - loss: 1.0036\nEpoch 44/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0033\nEpoch 45/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.9903\nEpoch 46/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.9944\nEpoch 47/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.0087\nEpoch 48/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.9777\nEpoch 49/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.9600\nEpoch 50/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.9519\nEpoch 51/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.9469\nEpoch 52/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.9440\nEpoch 53/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.9418\nEpoch 54/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.9330\nEpoch 55/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.9257\nEpoch 56/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.9206\nEpoch 57/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.9203\nEpoch 58/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.9157\nEpoch 59/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.9057\nEpoch 60/500\n16/16 [==============================] - 0s 6ms/step - loss: 0.9054\nEpoch 61/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.8994\nEpoch 62/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.8904\nEpoch 63/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.9055\nEpoch 64/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.8925\nEpoch 65/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.8871\nEpoch 66/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.8740\nEpoch 67/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.8682\nEpoch 68/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.8636\nEpoch 69/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.8570\nEpoch 70/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.8566\nEpoch 71/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.8549\nEpoch 72/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.8428\nEpoch 73/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.8374\nEpoch 74/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.8300\nEpoch 75/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.8260\nEpoch 76/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.8264\nEpoch 77/500\n16/16 [==============================] - 0s 6ms/step - loss: 0.8166\nEpoch 78/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.8128\nEpoch 79/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.8202\nEpoch 80/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.8060\nEpoch 81/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.7981\nEpoch 82/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.7948\nEpoch 83/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.7812\nEpoch 84/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.7767\nEpoch 85/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.7708\nEpoch 86/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.7798\nEpoch 87/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.7657\nEpoch 88/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.7626\nEpoch 89/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.7553\nEpoch 90/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.7480\nEpoch 91/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.7406\nEpoch 92/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.7371\nEpoch 93/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.7292\nEpoch 94/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.7212\nEpoch 95/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.7146\nEpoch 96/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.7140\nEpoch 97/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.7174\nEpoch 98/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.7123\nEpoch 99/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.7052\nEpoch 100/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.6898\nEpoch 101/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.6823\nEpoch 102/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.6790\nEpoch 103/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.6758\nEpoch 104/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.6725\nEpoch 105/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.6656\nEpoch 106/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.6684\nEpoch 107/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.6480\nEpoch 108/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.6511\nEpoch 109/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.6348\nEpoch 110/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.6280\nEpoch 111/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.6224\nEpoch 112/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.6195\nEpoch 113/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.6112\nEpoch 114/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.6126\nEpoch 115/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.6066\nEpoch 116/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.6015\nEpoch 117/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.5879\nEpoch 118/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.5961\nEpoch 119/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.5948\nEpoch 120/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.5731\nEpoch 121/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.5668\nEpoch 122/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.5626\nEpoch 123/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.5611\nEpoch 124/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.5469\nEpoch 125/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.5405\nEpoch 126/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.5531\nEpoch 127/500\n16/16 [==============================] - 0s 6ms/step - loss: 0.5405\nEpoch 128/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.5552\nEpoch 129/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.5488\nEpoch 130/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.5176\nEpoch 131/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.5128\nEpoch 132/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.5066\nEpoch 133/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.5059\nEpoch 134/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.4907\nEpoch 135/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.4853\nEpoch 136/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.4851\nEpoch 137/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.4793\nEpoch 138/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.4661\nEpoch 139/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.4639\nEpoch 140/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.4554\nEpoch 141/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.4523\nEpoch 142/500\n16/16 [==============================] - 0s 6ms/step - loss: 0.4564\nEpoch 143/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.4531\nEpoch 144/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.4346\nEpoch 145/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.4473\nEpoch 146/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.4362\nEpoch 147/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.4297\nEpoch 148/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.4152\nEpoch 149/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.4096\nEpoch 150/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3988\nEpoch 151/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.3986\nEpoch 152/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3949\nEpoch 153/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.4072\nEpoch 154/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.3801\nEpoch 155/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3745\nEpoch 156/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.3695\nEpoch 157/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3700\nEpoch 158/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3586\nEpoch 159/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.3543\nEpoch 160/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3486\nEpoch 161/500\n16/16 [==============================] - 0s 6ms/step - loss: 0.3473\nEpoch 162/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3361\nEpoch 163/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3382\nEpoch 164/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.3299\nEpoch 165/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3252\nEpoch 166/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.3198\nEpoch 167/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3132\nEpoch 168/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.3072\nEpoch 169/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.3017\nEpoch 170/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.2958\nEpoch 171/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.2951\nEpoch 172/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.3035\nEpoch 173/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.2812\nEpoch 174/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.2539\nEpoch 175/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.2436\nEpoch 176/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.2449\nEpoch 177/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.2336\nEpoch 178/500\n16/16 [==============================] - 0s 6ms/step - loss: 0.2215\nEpoch 179/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.2180\nEpoch 180/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.2266\nEpoch 181/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.2118\nEpoch 182/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.2082\nEpoch 183/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.2031\nEpoch 184/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.1901\nEpoch 185/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1775\nEpoch 186/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.1784\nEpoch 187/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.1723\nEpoch 188/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.1702\nEpoch 189/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.1730\nEpoch 190/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1489\nEpoch 191/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.1467\nEpoch 192/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1448\nEpoch 193/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.1451\nEpoch 194/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.1461\nEpoch 195/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1296\nEpoch 196/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.1383\nEpoch 197/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1404\nEpoch 198/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.1314\nEpoch 199/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.1184\nEpoch 200/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1060\nEpoch 201/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.1038\nEpoch 202/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1109\nEpoch 203/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0900\nEpoch 204/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0990\nEpoch 205/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1123\nEpoch 206/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0957\nEpoch 207/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0776\nEpoch 208/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0724\nEpoch 209/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0729\nEpoch 210/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0663\nEpoch 211/500\n16/16 [==============================] - 0s 6ms/step - loss: 0.0630\nEpoch 212/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0596\nEpoch 213/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.0543\nEpoch 214/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0559\nEpoch 215/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0566\nEpoch 216/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0483\nEpoch 217/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0449\nEpoch 218/500\n16/16 [==============================] - 0s 2ms/step - loss: 1.2690\nEpoch 219/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.2741\nEpoch 220/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1305\nEpoch 221/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.1182\nEpoch 222/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1132\nEpoch 223/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1072\nEpoch 224/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.1050\nEpoch 225/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0999\nEpoch 226/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0985\nEpoch 227/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0970\nEpoch 228/500\n16/16 [==============================] - 0s 7ms/step - loss: 0.0926\nEpoch 229/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.0903\nEpoch 230/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0929\nEpoch 231/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.1014\nEpoch 232/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.1012\nEpoch 233/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0805\nEpoch 234/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.0771\nEpoch 235/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0743\nEpoch 236/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0781\nEpoch 237/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0716\nEpoch 238/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.0675\nEpoch 239/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0714\nEpoch 240/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.0667\nEpoch 241/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.0611\nEpoch 242/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0600\nEpoch 243/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0566\nEpoch 244/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0547\nEpoch 245/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0513\nEpoch 246/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.0511\nEpoch 247/500\n16/16 [==============================] - 0s 3ms/step - loss: 0.0641\nEpoch 248/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0481\nEpoch 249/500\n16/16 [==============================] - 0s 5ms/step - loss: 0.0409\nEpoch 250/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0419\nEpoch 251/500\n16/16 [==============================] - 0s 4ms/step - loss: 0.0405\nEpoch 252/500\n16/16 [==============================] - 0s 2ms/step - loss: 0.0351\nEpoch 253/500\n 1/16 [>.............................] - ETA: 0s - loss: 0.0364",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "39e8219e19984f5cae7eaed66f93755b",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "model.summary()",
      "metadata": {
        "source_hash": "4e6a3b95",
        "execution_start": 1720545783046,
        "execution_millis": 42,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "1a0f16d6196d43949806d3cdfc2a2a8c",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Model: \"sequential_16\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n simple_rnn_21 (SimpleRNN)   (None, 3, 25)             675       \n                                                                 \n simple_rnn_22 (SimpleRNN)   (None, 3, 25)             1275      \n                                                                 \n simple_rnn_23 (SimpleRNN)   (None, 25)                1275      \n                                                                 \n dense_14 (Dense)            (None, 1)                 26        \n                                                                 \n=================================================================\nTotal params: 3,251\nTrainable params: 3,251\nNon-trainable params: 0\n_________________________________________________________________\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "fdd20e3f3f024ebc8405a135db107959",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "print(X_test)",
      "metadata": {
        "source_hash": "67ca0508",
        "execution_start": 1720545784064,
        "execution_millis": 109,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "9aad53c8dad94b158022dfd5c07ac2b4",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "[[501, 502, 503], [502, 503, 504], [503, 504, 505]]\n",
          "output_type": "stream"
        }
      ],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "356935f885ec45ca9fa9b40762a8cdbc",
      "content_dependencies": null
    },
    {
      "cell_type": "code",
      "source": "model.predict(np.array(X_test))",
      "metadata": {
        "source_hash": "dcc27b40",
        "execution_start": 1720545784895,
        "execution_millis": 342,
        "deepnote_to_be_reexecuted": false,
        "cell_id": "e78f70f3a63d42fa8a72d0889fa389e6",
        "deepnote_cell_type": "code"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "1/1 [==============================] - 0s 301ms/step\n",
          "output_type": "stream"
        },
        {
          "output_type": "execute_result",
          "execution_count": 84,
          "data": {
            "text/plain": "array([[504.00784],\n       [505.00827],\n       [506.00858]], dtype=float32)"
          },
          "metadata": {}
        }
      ],
      "outputs_reference": null,
      "execution_count": null,
      "block_group": "5b430001d1fa4ce592697eb8fb5ca39a",
      "content_dependencies": null
    },
    {
      "cell_type": "markdown",
      "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f5ed8ee2-3d40-4858-844e-fc002cc3a8df' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
      "metadata": {
        "created_in_deepnote_cell": true,
        "deepnote_cell_type": "markdown"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "deepnote_notebook_id": "8d4d145408cc4a24b9710f01c4510b44",
    "deepnote_execution_queue": []
  }
}